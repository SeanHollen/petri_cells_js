<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>petri_cells</title>
  <link rel="stylesheet" href="../styles.css" />
  <link rel="stylesheet" href="./styles.css" />
</head>

<body>
  <div class="outer-section">
    <div class="section">
      <p><a href="../">back to sim</a></p>
      <h1>Petri Cells BFF: A Simulation of "Artificial Life"</h1>
      <p>This is the first high-complexity replicator I got, in an early version of the program. It's the result that
        made me jump out of
        my chair, and say, “I am a god”:</p>
      <p><img src="./media/earliest_life.png" alt="life overtakes the grid from the right"></p>
      <h2 id="what-is-petri-cells-bff-">What is Petri Cells BFF?</h2>
      <p>I heard about this <a href="https://www.youtube.com/watch?v=EpRRwgyeBak">Sabine Hossenfelder video</a>
        discussing
        a <a href="https://arxiv.org/pdf/2406.19108">a paper</a> that was released in august, on how “artificial life”
        in
        the form of executable programs could emerge organically from noise.</p>
      <p>This paper sits at the intersection of several different topics which are very interesting to me - languages
        and
        computation, clever visualizations, origins of life, virtual evolution, and more. So I created an <a
          href="../">interactive visualization</a> of the concept. </p>
      <p>I more or less reproduce the research paper, with only slight modifications, and a different UI. This writeup
        will describe how the simulation works, and some of the results.</p>
      <p>You’ve probably heard of the the prime example of cellular automata, Conway’s Game of Life. Example <a
          href="https://seanhollen.com/conway">here</a>, a program delivers emergent complexity out of simple
        interaction
        rules.</p>
      <p>There are many cellular automata variants with hard-coded rules for cell interaction. But let’s take things a
        step further: what if we allow variation in how the different cells on the grid behave? </p>
      <p>In this project, every cell is is a self-contained computer program. These programs are composed of 10
        principle
        executable “instructions”, which I will discuss in more detail later. For the purpose of visualization, we can
        assign each instruction a unique color. As the default setting, each program will be 64 instructions long. Then,
        each program can be represented as an 8x8 square “cell”, like this.</p>
      <p><img src="./media/single_cell.png" width="100px" , height="100px" alt="an 8x8 colorful cell"></p>
      <p>Okay. If the cells are each literally self-contained programs, what is the <em>programming language</em>? For
        that, we repurpose a language which, though esoteric, you may have heard of: <a
          href="https://en.wikipedia.org/wiki/Brainfuck">Brainfuck</a>. A super-minimalist language, it was made with
        the
        goal of creating the smallest possible compiler for a Turing-complete language.</p>
      <p>Supposedly, Brainfuck (BF) wasn’t meant for practical uses, but rather as a theoretical exercise in language
        design. That doesn’t apply here, though, because the language is actually chosen for it’s practicality. Because
        the syntax is so minimalist, we can randomly create any program, and it will be executable.</p>
      <p>Actually, we are not going to be using vanilla BF, but rather, a variant designed for programs to modify
        themselves, “BFF”. Whereas standard BF takes in an input and returns an output, BFF will <em>write</em> to the
        same tape that it <em>reads</em> from, modifying itself in real-time.</p>
      <p>The instruction set for BFF is below.</p>
      <p><img src="./media/program_instructions.png"
          alt="less than symbol: head0 = head0 - 1, > head0 = head0 + 1; { head1 = head1 - 1; } head1 = head1 + 1; - tape[head0] = tape[head0] - 1; + tape[head0] =; tape[head0] + 1; . tape[head1] = tape[head0]; , tape[head0] = tape[head1]; [ if (tape[head0] == 0): jump forwards to matching ] command.; ] if (tape[head0] != 0): jump backwards to matching [ command.">
      </p>
      <p>There are a few other rules to cover. The program terminates if it reaches a limit on the number of reads (2^10
        for me, 2^13 in the paper). If a value appears in the program which is not in the instruction set, it will not
        be
        executed - in theory, this can be used to store memory.</p>
      <p>Picture each program/cell as an array of integers (in the original paper, they’re arrays of bytes). 9 of those
        values map to the instructions listed above - your "<code>&lt;</code>"s, your "<code>]</code>"s, etc. The value
        of
        0
        is read to determine whether to enter/exit loops. Everything else is a no-op.</p>
      <p>To play with and test the BFF interpreter, I built a visual version.</p>
      <p><img src="./media/bf_interpreter.gif" alt="the BFF language executing, animation"></p>
      <p>On the backend, I store programs as arrays of integers, but I also can print a program as a
        human-readable-string
        that read as Brainfuck code. If you click on a cell, it will give you both formats. You can think of the
        human-readable-string format as the “lossy” format, and the integer-array format as the “lossless” format.</p>
      <p>From what I can tell, the original research paper just stores all of the programs as strings. This has a few
        advantages (and probably some disadvantages), and is one of the biggest ways that our implementations differ.
        I’ll
        discuss the language mapping more close to the end of this post.</p>
      <p>Either way, we now have an interpreter for executing these programs. We can use it in really cool ways to
        recursively recombine programs with each other. </p>
      <p>To combine programs with each other and make something new, there are 3 steps:</p>
      <ol>
        <li><strong>The programs are concatenated</strong>, literally like concatenating arrays or strings, into one
          program.</li>
        <li><strong>The program is executed</strong>, using the compiler for BFF (self-modifying Brainfuck). Since the
          program makes changes to itself, the result will be a modified program.</li>
        <li><strong>The program is split in half</strong>, resulting in 2 new programs.</li>
      </ol>
      <p>And the two new programs take the place of the original programs. This process can be expressed as one line of
        code: <code>a, b = split(execBff(a + b))</code>.</p>
      <h2 id="grid-interactions">Grid Interactions</h2>
      <p>Now that you know the chemistry behind transforming 2 programs into 2 programs, we can introduce: THE GRID.</p>
      <p><img src="./media/the_grid.png" alt="a grid of cells, each sub-cell is itself an 8x8 grid of diverse colors">
      </p>
      <p>The rules for the grid are quite simple. Each epoch, we iterate through all of the cells in the grid. The cell
        randomly chooses another cell with in its “radius” of adjacency (by default, no more than 2 away on each axis).
        We
        skip a cell if it the cell it’s trying to pair with has already been reacted with in the same epoch (this
        probably
        helps with parallel processing in the original, but doesn’t make a big difference in my version). The cells
        react.
        Rinse and repeat.</p>
      <p>At risk of burying the interesting bit, if you run this simulation, then some of the programs will
        spontaneously
        acquire the ability to self-replicate and dominate the grid.</p>
      <blockquote>
        <p>Speaking about “artificial life”, one little issue: scientists still can’t agree about what “life” means. But
          one thing they do agree on is that the ability to self-replicate is part of it. This is why most of the
          studies
          on the “origin of life” focus on reproduction.
          -Sabine </p>
      </blockquote>
      <p>What I like about the “life” that emerges is how much of a stark phase transition it is. You don’t have to
        squint
        and imagine it. In many cases, a pattern will suddenly dominate the grid in an undeniable way.</p>
      <p><img src="./media/early_replicator.gif" width="500px" height="500px"
          alt="grid starts out pretty random, and then one pattern comes to dominate"></p>
      <h2 id="early-signs-of-life">Early Signs of Life</h2>
      <p>What we quickly noticed, with the default settings (a small grid, no noise), that there are basically 2 types
        of
        life which come to dominate.</p>
      <p><strong>Firstly</strong>, some life comes about almost immediately in the chaotic conditions under which the
        board is initialized, yielding some interesting patterns. For brevity, I will call this kind of life “complex
        life”.</p>
      <p><img src="./media/early_life.gif" alt="grid starts out pretty random, and then one pattern comes to dominate">
      </p>
      <p>No matter how many times I see this, I always get excited when it occurs. It never gets old.</p>
      <p>These early-game replicators are some of the coolest, but they’re rare, only occurring maybe 1 out of every 10
        runs. The strategy for finding them is to spam restart the simulation, letting it run no more than 200 epochs,
        until you get one. And when it comes to complex life, you’ll know it when you see it.</p>
      <p>The <strong>second</strong> kind of life is very basic bi-color patterns which emerge later on. These are
        actually “sub-strings” (patterns <em>within</em> the cell) which propagate themselves outward eventually to
        neighboring cells, and eventually the whole grid. I’ll call these replicators “simple life”</p>
      <p><img src="./media/bicolor.gif" alt="a basic 2-color pattern takes over the grid"></p>
      <p>Another thing you notice is the distinction between “surviving” and “replicating”. Most cells will eventually
        settle into a state that is relatively change-resistant. There is a surprising level of consistency within the
        board, as most can last a number of epochs with relatively few changes. Becoming a “persister” is in itself is a
        kind of adaptation, so to speak. But the replicators take things quite a step further than the pesisteres, by
        multiplying themselves across the grid.</p>
      <h2 id="noise">Noise</h2>
      <p>After a while, I got bored of this, so I introduced of noise options. The options are “kill cells” and “kill
        instructions”.</p>
      <p><strong>Kill cells</strong> will randomly pick a certain number of cells from the grid and replace them with
        entirely new random instruction sets.</p>
      <p>Killing cells reliably creates complex life. If you run program long enough while killing cells at a 3%
        rate, it will virtually always result in an interesting pattern coming to dominate the board.</p>
      <p><img src="./media/kill_cells.gif"
          alt="the grid is random, but also certain cells are getting randomly replaced. life emerges anyway"></p>
      <p>I attribute this to the power of RNG. The original paper seems to downplay the need for background random
        mutations, and emphasize that life can emerge merely from interactions between cells. Contrary to this, I found
        that if you’re after complex life, noise definitely helps.</p>
      <p>How I would describe it is, after the early stage of the simulation, the game state becomes “ossified”. The
        cells
        have to become change-resistant, and there is not enough entropy in the system to support the amount of
        <em>variance</em> required to optimally seek out complex replicators.
      </p>
      <p>This explains why, under default conditions, complex life tends to emerge early on. Since the grid is randomly
        initialized, there is a lot of variance in the system. Later, replicators do emerge eventually, but only as
        simple
        life, because there’s not enough bandwidth for anything more complex.</p>
      <p><strong>Kill instructions</strong> is another kind of noise. Instead of picking entire cells to kill, it will
        randomly replace individual instructions (codes) across the board.</p>
      <p>The effects of this action are paradoxical and interesting. If life has not yet emerged, then it will make it
        harder for it to emerge in the first place. But if life has already emerged, and you subsequently turn on “kill
        instructions”, it will stimulate the <em>changes</em> and <em>evolution</em> of that life.</p>
      <p><img src="./media/kill_instructions_2.gif"
          alt="life has emerged, but is changing and shifting, and color is mutating"></p>
      <p>This is interesting to watch. In the absence of “kill cell” mutations, mutating and evolving life is actually
        quire rare. Complex life usually maintains a stagnant, unchanging phenotype. But if you introduce this kind of
        noise, then it will consistently and continually change. </p>
      <p>It’s unsurprising that noise would have the effect of “shuffling” the genome, but it is quite surprising that
        the
        cells are resistant enough that they maintain the ability to self-replicate.</p>
      <h2 id="other-customizations">Other customizations</h2>
      <p><strong>Cell Size</strong></p>
      <p>By default, a program is 64 instructions long - a square number, so it can fit into a cell. But there’s no
        reason
        it can’t be any other square number! I implemented the ability to create different-length programs: 49, 36, 25,
        15, and so on. When you run the sim with smaller-sized programs, one thing you notice is that terminal states
        are
        more likely. Here, “terminal state” refers to a static, totally unchanging board.</p>
      <p><img src="./media/terminal_state.gif" width="500px" height="500px"
          alt="it's a grid with fewer pixels. the colors shift around a bit, but then end in a 'terminal state', and there is no movement on the grid after that.">
      </p>
      <p>To some extent, this is expected, because if programs are smaller, there are fewer permutations. It also makes
        me
        wonder if all programs will eventually resolve into either a terminal or looping state. In principle, the answer
        is yes, but how long will it take? Furthermore, “endgame” states are likely to have replicators, which makes the
        board look ordered - a fact which runs contrary to the intuitions based on entropy (or does it?). I should study
        this more.</p>
      <p><strong>Unique Cell Counter and Compression Statistic</strong></p>
      <p>The original paper computes complexity precisely with special formulas. I tried to use the same formula they used, but found that the performance cost was too high. (Maybe they did it in a faster way).</p>
    <p>Instead, I measure 2 relatively simple proxy metrics each epoch, both of which are surprisingly informative:</p>
    <ul>
    <li>The number of unique cells</li>
    <li>What I call &quot;compression&quot;, which is just the ratio of the original length and the compressed length.</li>
    </ul>
    <p>I compress with Pako, for no particular reason, except that it was the first library that worked.</p>
    <p>An interesting result from these metrics is the heterogeneity of replicators. </p>
    <p>Some replicators are homogeneous, allowing only a couple variations, where others are heterogeneous, allowing hundreds of different variants - especially at first. I’m not sure which kind are my favorite. </p>
    <p>Despite the diversity of the the heterogeneous replicators, which allow for many subtle variants, there is rarely any confusion whether a group of cells is part of the same “species”.</p>
      <p><strong>History</strong></p>
      <p>To save time, you may want to run the simulations on high speeds, but that can make it easy to miss important
        events. Therefore, these simulations store their history, allowing you to rewind (even run the simulation in
        reverse). </p>
      <p>To save on space, grid states are saved in 50-epoch increments when you run the animation. This is not a bug; I thought that 
        storing <em>every</em> increment would be overkill on memory. If you’re still
        worried about space, you can turn it off (for the most part) by running this command from the console.</p>
      <pre><code>controller.miscSettings.<span class="hljs-attr">storeStateWhenRunning</span> = <span class="hljs-literal">false</span>;
</code></pre>
      <p><strong>Interpreter randomizer</strong></p>
      <p>For the purpose of this simulation, I arbitrarily map the underlying 32-bit value of 1 to “&lt;”, I map 2 to
        “&gt;”, I map 3 to “{“, and so on for the BFF language. Thus, if you have a “&gt;” instruction, and you add 1 to
        it, you get a “{“. This impacts how the programs might mutate.</p>
      <p>But there’s no reason, in principle, to privilege this particular mapping. We could, just as well, have 1 map
        to
        “{“, 2 map to “&lt;“, or whatever. </p>
      <p>Therefore, my simulation also supports the ability to reconfigure the language, by editing (or even
        randomizing)
        the mapping between the underlying data values and the BFF instructions. This impacts both the grid and the BFF
        interpreter. Changes to the language will come into effect as soon as you advance either of these
        visualizations.
        It will update the colors on the grid to reflect the update. </p>
      <p><strong>Cell Viewer</strong></p>
      <p>If you click on a cell, it will receive a black border, and the details of the cell will appear at the bottom
        of
        the grid. The details consist of its location, it’s integer-array representation, and its human-readable-string
        representation.</p>
      <p>From there, you can edit the contents of the cell. Changes to the cell will take effect on the grid.</p>
      <p>As that cell reacts with other cells, the cells that it reacts with will receive a thin green border.</p>
      <p><strong>Randomizing the pointer start position</strong></p>
      <p>When two cells are paired up, their programs are concatenated in sequence. This gives the first cell a big
        advantage over other cell, because the pointer starts at the beginning of the sequence, executing those
        instructions first, and it might not even reach the second half. To remedy this, I could introduce a variant
        which
        drops the pointer randomly somewhere, and ends when it makes a full rotation.</p>
      <p>You can turn on this setting by running this command in the console.</p>
      <pre><code>controller.miscSettings.<span class="hljs-attr">toRandomPivot</span> = <span class="hljs-literal">true</span>;
</code></pre>
      <p>I have noticed anecdotally that complex life does not emerge when this setting is switched on. </p>
      <p><strong>Super large grids</strong></p>
      <p>By using Three.js, I eventually got it working with large grids. Case in Point:</p>
      <p><img src="./media/large grid.png"
        alt="a 100x100 grid, with different cluster of life encroaching on each other"></p>
      <p><strong> Grid Zooming</strong></p>
      <p>The site currently supports larger grids. To facilitate that, you can zoom and pan around. However, for super
        large grids, the zooming gets quite laggy.</p>
      <h2 id="versions">Versions</h2>
      <p>This project has gone through a few iterations so far.</p>
      <p><strong>Version 0: Kivy</strong></p>
      <p>My initial mockup of the grid, along with the BFF interpreter visualization, was created in Kivy. Although I thought it was fun to experiment with a new framework, 
        I quickly yearned for the convenience of JS - and the ability to easiliy run the simulation on the web.
      </p>
      <p><strong>Version 1: Vanilla HTML/JS</strong></p>
      <p>In the original JS implementation, each cell was made a separate canvas element. Every frame, the application would remove and re-creating
        all of the canvas objects.</p>
      <p>Unspurprisingly, Version 1 was initially very slow.</p>
      <p>The first obvious improvement was to not do that. Reuse existing canvas objects, rather than delete and re-create updated versions.</p>
      <p>Optimization #2 involved batching of the updates. Previously, the program was drawing each tile every epoch using the <code>fillRect()</code> function. 
        So the speedup was to precompute the updates, and sort them by color. Then, for each of those batches:
      <p>
        <ul>
        <li>Run <code>ctx.fillStyle = color</code></li>
        <li>Run <code>ctx.rect()</code>, for each tile</li>
        <li>Run <code>ctx.fill()</code></li>
        </ul>
        <p>That way, the "fill" step happens once per cell (program), not once per tile (instruction).</p>
        <p>I did get a really fascinating bug in this version. There was a bug that caused certain programs to become much (ie 10x) longer than they were supposed to be. But this did not break the UI, because the UI was flexible enough to <em>allow</em> for super long programs:</p>
        <p><img src="./media/weird_bug.gif"
          alt="certain random cells look really weird and unusually complex"></p>
        <p>The buggy cells are pretty blurry, becuase there aren't enough pixels to show them fully in this version - still, it looks interesting.</p>
        <p>This bug could never occur in later versions, because (due to optimizations), later versions don't allow different cells to be differently-lengthed in the UI.</p>
        <strong>Version 2: ThreeJS</strong></p>
      <p>The speedup in Version 2 wasn&#39;t good enough. To enable larger grids, and better usability, I wanted to
        support zooming and panning. I achieved this with ThreeJS.</p>
        <p>The intuitive &quot;first attempt&quot; at using Three JS is:</p>
        <ul>
        <li>Each program / &quot;cell&quot; corresponds to a Three JS &quot;Group&quot;. Together, they make up the grid.</li>
        <li>A program contains a list of instructions. Each &quot;instruction&quot; corresponds to an individual Three JS PlaneGeometry square. Together, they make up the sub-grids.</li>
        </ul>
        <p>But that wasn&#39;t good enough. On a 20x20 grid, with programs 64-long, that&#39;s 400x64 individual objects to render, which makes the updates very slow.</p>
        <p>The solution? Play with meshes. You can manually assign the vertices and indices in the mesh, and render each cell as a single mesh. It gets a little messy, but it certainly speeds things up. Now you have one object per cell, not one object per instruction.</p>
        <p>But that still wasn&#39;t good enough. One object per cell is still too many objects, and Three JS can only handle so many objects. The basic mesh optimization worked for my standard 20x20 grids. But as soon as you tried to make super large, 200x200 grids, then zooming froze up significantly. </p>
        <p>The solution? Render the entire board as one giant mesh, of course! This was pretty finicky, because now we need to manually calculate the positions and sub-positions of the cells and tiles, respectively.</p>
        <p>But that still wasn&#39;t good enough. I now got this error: <code>WebGL warning: drawElementsInstanced: Context&#39;s max indexCount is 30000000, but 34560000 requested</code> So Three JS has a limit on how big meshes could be? Who knew!</p>
        <p>The solution? Divide the number of vertices that you need by the max number of vertices per mesh, then generate that number of meshes. Make all the mesh objects basically the same, except that you &quot;assign&quot; different cells to different meshes, to even out the load. You then create all the cells the same as before, but belonging to different meshes.</p>
        <p>That&#39;s the version that exists now. Is it good enough? I don&#39;t think so. You can make super large grids, but then zooming is super laggy (which annoyingly reverts back to page scrolling behavior). Feel free to test the limits yourself, and make suggestions. </p>
        <p>The solution? IDK, but I think it&#39;s good enough for now.</p>
      <p><strong>Version 3?</strong></p>
      <p>A future version 3 could consist of a few things. </p>
      <ul>
        <li>The original paper experiments with several different minimalist programming languages My version only supports BFF, but it would be nice to extend it.</li>
        <li>The original paper creates graphs of complexity over time. I think this would be fun, but it&#39;s a tricky feature to shoehorn in.</li>
        <li>I think some sort of &quot;full screen mode&quot; would be cool.</li>
        <li>My performance was faster than I expected, given that the whole simulation, BFF and all, runs client-side with basic JS. But if I wanted to &quot;next-level&quot; my simulation, the next step would be to use GPUs - maybe with WebGPU?</li>
        </ul>
    </div>
  </div>
</body>

</html>